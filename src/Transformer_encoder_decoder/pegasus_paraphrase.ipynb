{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pegasus_paraphrase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cHu7nBKKjQTqvQIRyfsYXkPC4y0veyF5",
      "authorship_tag": "ABX9TyM6vHUsa3hwEIazbvxgfX4q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Augment4Gains/blob/main/pegasus_paraphrase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKDejEfrrkZh"
      },
      "source": [
        "# Using a pre-trained Transformer Encoder-Decoder based Paraphraser"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oJZEy3KtphC"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Getting necessary libraries\n",
        "!pip install -U transformers\n",
        "!pip install sentencepiece\n",
        "\n",
        "import json\n",
        "import torch\n",
        "import sentencepiece\n",
        "from tqdm import tqdm\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, BertTokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EpUtRKc35Bf"
      },
      "source": [
        "# Using a standard model\n",
        "tokenizer_model_name = 'google/pegasus-large'\n",
        "\n",
        "# Using a pre-trained community model\n",
        "paraphrasing_model_name = 'tuner007/pegasus_paraphrase'\n",
        "\n",
        "torch_device = 'cuda'\n",
        "if torch.cuda.is_available() == False:\n",
        "  torch_device = 'cpu'\n",
        "\n",
        "tokenizer = PegasusTokenizer.from_pretrained(tokenizer_model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(paraphrasing_model_name).to(torch_device)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2FxfvLyK63A"
      },
      "source": [
        "def get_paraphrase(input_text, num_return_sequences = 2, num_beams = 10):\n",
        "  batch = tokenizer([input_text], \n",
        "                    truncation = True,\n",
        "                    padding = 'longest',\n",
        "                    max_length = 128,\n",
        "                    return_tensors = 'pt').to(torch_device)\n",
        "\n",
        "  translated = model.generate(**batch,\n",
        "                              max_length = 128,\n",
        "                              num_beams = num_beams,\n",
        "                              num_return_sequences = num_return_sequences,\n",
        "                              temperature = 1.5)\n",
        "  \n",
        "  target = tokenizer.batch_decode(translated,\n",
        "                                  skip_special_tokens = True)\n",
        "  \n",
        "  return target"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt8CTX4avo4h",
        "outputId": "607df252-d9d0-4d66-c92f-a0ce3afeda83"
      },
      "source": [
        "# Viewing Sample Paraphrases\n",
        "\n",
        "examples = ['you should watch louis le vau \\'s latest video . steven oh of tyt is disturbing as hell and makes me hope that jimmy dore wakes the left up .',\n",
        "            'kill yourself you whiny , self-righteous faggot .',\n",
        "            'but why do they make that face']\n",
        "\n",
        "for example in examples:\n",
        "  print('Source: ' + str(example))\n",
        "  responses = get_paraphrase(example)\n",
        "  print('Primary Paraphrase: ' + str(responses[0]))\n",
        "  print()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source: you should watch louis le vau 's latest video . steven oh of tyt is disturbing as hell and makes me hope that jimmy dore wakes the left up .\n",
            "Primary Paraphrase: louis le vau's latest video is disturbing and makes me hope that jimmy dore wakes the left up.\n",
            "\n",
            "Source: kill yourself you whiny , self-righteous faggot .\n",
            "Primary Paraphrase: You are self-righteous and should kill yourself.\n",
            "\n",
            "Source: but why do they make that face\n",
            "Primary Paraphrase: Why do they make that face?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cx3G5pYvu31"
      },
      "source": [
        "# Generating the Augmented Training Data\n",
        "set_type = 'reddit'\n",
        "\n",
        "# Reference to the absolute path in Google Drive\n",
        "data_path = 'drive/My Drive/Augment4Gains/data/' + set_type\n",
        "\n",
        "with open(data_path + '/' + 'train.json', 'r+') as f:\n",
        "  raw_train = json.load(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj_zq6f0FvLA",
        "outputId": "a5444208-6475-499e-c80f-830c02c55f9c"
      },
      "source": [
        "# Getting the Augmented Datapoints\n",
        "augmented_data = []\n",
        "limit = len(raw_train)\n",
        "\n",
        "test_mode = False\n",
        "if test_mode == True:\n",
        "  limit = 10\n",
        "\n",
        "for index, unit in enumerate(tqdm(raw_train, total = limit)):\n",
        "  if index > limit - 1:\n",
        "    break\n",
        "  raw_text = unit['source']\n",
        "  target = get_paraphrase(example)[0]\n",
        "  new_unit = unit\n",
        "\n",
        "  new_unit['source'] = target\n",
        "  augmented_data.append(new_unit)\n",
        "\n",
        "with open(data_path + '/' + 'paraphrased_train.json', 'w+') as f:\n",
        "  json.dump(augmented_data, f)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15619/15619 [2:29:46<00:00,  1.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkswWKTF040"
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}